import fitz
import re

# ================= ğŸ›ï¸ æ ¸å¿ƒé…ç½® =================

# å­—ä½“å¤§å°æ˜ å°„è¡¨ï¼šæ ¹æ®å­—å·å¤§å°å†³å®š Markdown çš„å‰ç¼€
# æ³¨æ„ï¼šæµ®ç‚¹æ•°åŒ¹é…å…è®¸å¾®å°è¯¯å·® (Â±0.5)
FONT_MAP = {
    29.0: "# ",       # ä¸€çº§æ ‡é¢˜ï¼ˆå®¹é”™ï¼‰
    16.6: "# ",       # ä¸€çº§æ ‡é¢˜ï¼ˆå®¹é”™ï¼‰
    14.4: "# ",       # ä¸€çº§æ ‡é¢˜
    13.0: "## ",      # äºŒçº§æ ‡é¢˜
    11.0: "### ",     # ä¸‰çº§æ ‡é¢˜
    # 11.0: "SUBTITLE",  # å‰¯æ ‡é¢˜ï¼ˆä¼šè¢«åŠ ç²—å¤„ç†ï¼‰ä¹Ÿå¯èƒ½æ˜¯ 9.6
    7.4: "> ",        # é»˜è®¤å¼•ç”¨ï¼ˆé€šå¸¸ç”¨äºæ–‡æœ«å‡ºç‰ˆä¿¡æ¯ï¼Œä¼˜å…ˆçº§ä½äºå­—ä½“æ£€æµ‹ï¼‰
    # 9.6 æ­£æ–‡ï¼Œä¸åŠ å‰ç¼€
}

# é¡µé¢å¸ƒå±€å‚æ•°ï¼ˆå•ä½ï¼šPDFåæ ‡ç‚¹ï¼‰
# measure_margin: å·¦ä¾§æ–‡å­—è¾¹ç¼˜ 90ï¼Œç¼©è¿›å 110 â†’ INDENT_THRESHOLD=105
MARGIN_TOP_CUT = 110     # é¡¶éƒ¨è£å‰ªçº¿ï¼šå¿½ç•¥æ­¤é«˜åº¦ä»¥ä¸Šçš„é¡µçœ‰
MARGIN_BOTTOM_CUT = 520 # åº•éƒ¨è£å‰ªçº¿ï¼šå¿½ç•¥ Y > 520 çš„åŒºåŸŸ
DETECT_THRESHOLD = 40   # å…¨é¡µæ³¨è„šæ£€æµ‹é˜ˆå€¼ï¼šä»æ­¤é«˜åº¦æ‰å¼€å§‹æ£€æµ‹æ³¨è„š
INDENT_THRESHOLD = 105  # ç¼©è¿›é˜ˆå€¼ï¼šXåæ ‡å¤§äºæ­¤å€¼è§†ä¸ºæ–°æ®µè½ï¼ˆåˆ—å®å·1: å·¦90 ç¼©è¿›110ï¼‰
CENTER_THRESHOLD = 120  # å±…ä¸­é˜ˆå€¼ï¼šXåæ ‡å¤§äºæ­¤å€¼ä¸”ä¸ºé»‘ä½“ï¼Œè§†ä¸ºä¸‰çº§æ ‡é¢˜ (###)


# ================= âš™ï¸ è§£æå¼•æ“ =================
# Pageï¼ˆé¡µï¼‰ -> Blockï¼ˆå—ï¼‰ -> Lineï¼ˆè¡Œï¼‰ -> Spanï¼ˆç›¸åŒæ ·å¼ç‰‡æ®µï¼‰ -> Charï¼ˆå­—ç¬¦ï¼‰

class LeninParser:
    def __init__(self, output_base_dir):
        """
        åˆå§‹åŒ–è§£æå™¨
        :param output_base_dir: åŸºç¡€ç›®å½• (pathlib.Path å¯¹è±¡)
        """
        self.output_base_dir = output_base_dir
        self.img_counter = 0
        self.assets_dir = None  # ç”± parse_chapter_pages æŒ‰æ–‡ç« è®¾ç½®

        # === çŠ¶æ€å˜é‡ ===
        self.global_note_id = 1    # å…¨å±€æ³¨è„šè®¡æ•°å™¨ [^1], [^2]...
        self.all_footnotes = []    # å­˜å‚¨å½“é¡µæå–å‡ºçš„æ³¨è„šå†…å®¹
        self.body_buffer = []      # å­˜å‚¨æ­£æ–‡æ®µè½
        self.current_para = ""     # å½“å‰æ­£åœ¨æ‹¼æ¥çš„æ®µè½ç¼“å­˜

    def is_cjk(self, char):
        """æ£€æµ‹å­—ç¬¦æ˜¯å¦ä¸ºä¸­æ—¥éŸ©æ–‡å­—ï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦éœ€è¦åŠ ç©ºæ ¼ï¼‰"""
        if not char: return False
        return '\u4e00' <= char <= '\u9fff'

    def clean_text(self, text):
        """
        åŸºç¡€æ–‡æœ¬æ¸…æ´—
        [æ³¨æ„] è¿™é‡Œä¸å†ä½¿ç”¨ .strip() å»é™¤é¦–å°¾ç©ºæ ¼ï¼
        åŸå› ï¼šæˆ‘ä»¬éœ€è¦ä¿ç•™ span ä¹‹é—´çš„åŸå§‹ç©ºæ ¼ï¼Œä»¥ä¾¿åœ¨ process_spans_in_line
        ä¸­é€šè¿‡æ­£åˆ™æ™ºèƒ½è¯†åˆ« '## ä¸€ å‡ ç‚¹è¯´æ˜' è¿™ç§å¸¦åºå·çš„æ ‡é¢˜ã€‚
        """
        # ç§»é™¤ PDF ä¸­çš„æ¢é¡µæ ‡è®°
        text = re.sub(r'\[\s*æ¥\s*ä¸Š\s*é¡µ\s*\]', '', text)
        text = re.sub(r'\[\s*è½¬\s*ä¸‹\s*é¡µ\s*\]', '', text)
        return text

    def get_split_y(self, page):
        """
        è®¡ç®—æ­£æ–‡å’Œæ³¨è„šçš„åˆ†å‰²çº¿ (Split Line) Yåæ ‡
        åˆ—å®å…¨é›†ï¼šç”¨çŸ¢é‡æ¨ªçº¿ï¼ˆä»ä¸‹å¾€ä¸Šç¬¬ä¸€æ¡ï¼‰
        é€»è¾‘ï¼š
        1. ä¼˜å…ˆæ‰¾ get_drawings ä¸­çš„æ¨ªçº¿ï¼ˆå®½ 60â€“75ï¼‰ï¼Œéè¿ç»­ç ´æŠ˜å· blockï¼Œå–ä»ä¸‹å¾€ä¸Šç¬¬ä¸€æ¡
        2. å…¶æ¬¡æ‰¾ 'æ¥ä¸Šé¡µ' è¿™ç§å…¨é¡µæ³¨è„šæ ‡è®°
        """
        blocks = page.get_text("blocks")
        page_height = page.rect.height

        # 1. çŸ¢é‡æ¨ªçº¿ï¼ˆä»ä¸‹å¾€ä¸Šç¬¬ä¸€æ¡ï¼‰
        # é¡µçœ‰çº¿ï¼šå®½åº¦>200ï¼›æ­£æ–‡/æ³¨è„šåˆ†å‰²çº¿ï¼šå®½åº¦çº¦ 60â€“75
        drawings = page.get_drawings()
        h_lines = []
        for d in drawings:
            r = d.get("rect")
            # ç‰¹å¾åŒ¹é…
            if not r or r.height >= 5:
                continue
            w = r.width
            if 60 <= w <= 75:
                h_lines.append(r.y0)
        if h_lines:
            return max(h_lines) - 2  # ç¨å¾®å¾€ä¸Šæä¸€ç‚¹ä½œä¸ºåˆ†ç•Œçº¿

        # 2. æ‰«æå…¨é¡µæ³¨è„šæ ‡è®°
        check_count = 0
        for b in blocks:
            y0 = b[1]
            text = b[4].strip()
            if y0 > DETECT_THRESHOLD:
                if re.search(r'æ¥\s*ä¸Š\s*é¡µ', text):
                    return y0 - 1
                check_count += 1
                if check_count >= 5: break # åªæ£€æŸ¥é¡¶éƒ¨å‡ ä¸ªå—ï¼Œé¿å…è¯¯åˆ¤

        return page_height # æ²¡æ‰¾åˆ°åˆ†å‰²çº¿ï¼Œè¯´æ˜å…¨æ˜¯æ­£æ–‡

    def process_spans_in_line(self, line, page_note_queue):
        """
        [æ ¸å¿ƒå‡½æ•°] å¤„ç†å•è¡Œå†…çš„æ‰€æœ‰ spanï¼ˆç‰‡æ®µï¼‰ï¼Œè´Ÿè´£ï¼š
        1. å­—ä½“è¯­ä¹‰è¯†åˆ«ï¼ˆé»‘ä½“->ç²—ä½“ï¼Œæ¥·ä½“->æ–œä½“ï¼Œä»¿å®‹->å¼•ç”¨ï¼‰
        2. æ ‡é¢˜å±‚çº§åˆ¤å®š
        3. æ³¨è„šç¬¦å·æ›¿æ¢
        4. æ™ºèƒ½å»ç©ºï¼ˆä¿®å¤æ ‡é¢˜ç©ºæ ¼ï¼‰
        """
        spans = line["spans"]
        formatted_text = ""

        line_max_size = 0
        has_fangsong = False
        has_kaiti = False
        has_heiti = False

        # --- æ­¥éª¤ 1: é¢„æ‰«ææ•´è¡Œç‰¹å¾ ---
        for span in spans:
            if span["size"] > line_max_size: line_max_size = span["size"]
            font_lower = span["font"].lower()

            # æ¨¡ç³ŠåŒ¹é…å­—ä½“å
            if "fang" in font_lower:    # ä»¿å®‹ -> å¼•ç”¨
                has_fangsong = True
            elif "kai" in font_lower:   # æ¥·ä½“ -> æ–œä½“
                has_kaiti = True
            elif "hei" in font_lower or "bold" in font_lower: # é»‘ä½“/ç²—ä½“ -> åŠ ç²—
                has_heiti = True

        # --- æ­¥éª¤ 2: å†³å®šæ•´è¡Œçš„å‰ç¼€ (Markdown Syntax) ---
        line_prefix = ""
        mapped_prefix = ""

        # å…ˆçœ‹å­—å·æ˜ å°„
        if FONT_MAP:
            closest_size = min(FONT_MAP.keys(), key=lambda k: abs(k - line_max_size))
            if abs(closest_size - line_max_size) < 0.5:
                mapped_prefix = FONT_MAP[closest_size]

        # åˆ¤å®šä¼˜å…ˆçº§ï¼š
        # 1. å­—å·å·¨å¤§çš„æ ‡é¢˜ (#, ##)
        if mapped_prefix.startswith("#"):
            line_prefix = mapped_prefix
        # 2. å±…ä¸­çš„é»‘ä½“ -> å¼ºåˆ¶è§†ä¸ºä¸‰çº§æ ‡é¢˜ (###)
        elif has_heiti and line["bbox"][0] > CENTER_THRESHOLD:
            line_prefix = "### "
        # 3. ä»¿å®‹å­—ä½“ -> å¼•ç”¨å—
        elif has_fangsong:
            line_prefix = "> "
        # 4. 14å·å°å­— -> å¼•ç”¨å— (æ’é™¤æ¥·ä½“å’Œé»‘ä½“ï¼Œé¿å…è¯¯ä¼¤æ³¨è„šæˆ–å¼ºè°ƒæ–‡æœ¬)
        elif mapped_prefix == "> " and not has_kaiti and not has_heiti:
            line_prefix = "> "

        # å¦‚æœæœ‰å‰ç¼€ï¼Œå…ˆæ‹¼æ¥åˆ°ç»“æœä¸­
        if line_prefix.strip().startswith("#") or line_prefix.strip().startswith(">"):
            formatted_text += line_prefix

        # è®°å½•å½“å‰è¡Œçš„ç±»å‹ï¼Œç”¨äºé˜²ç²˜è¿é€»è¾‘
        last_type = None
        if line_prefix.strip().startswith("#"):
            last_type = "header"
        elif line_prefix.strip().startswith(">"):
            last_type = "blockquote"
        else:
            last_type = "body"

        # --- æ­¥éª¤ 3: é€ä¸ªå¤„ç† span (å†…å®¹æ‹¼æ¥ & è¡Œå†…æ ·å¼) ---
        for span in spans:
            text = span["text"]
            size = span["size"]
            flags = span["flags"]
            font_lower = span["font"].lower()

            text = self.clean_text(text)
            if not text: continue # ç©ºå†…å®¹è·³è¿‡

            current_type = "body"
            if size in FONT_MAP:
                span_closest = min(FONT_MAP.keys(), key=lambda k: abs(k - size))
                if abs(span_closest - size) < 0.5:
                    p = FONT_MAP[span_closest]
                    if p.startswith("#"): current_type = "header"

            clean_t = text.strip()
            # åˆ¤æ–­æ˜¯å¦ä¸ºçº¯æ ‡ç‚¹ï¼ˆç”¨äºé˜²æ­¢æ ‡é¢˜å› æ ‡ç‚¹è¢«åˆ‡æ–­ï¼‰
            is_punctuation = len(clean_t) == 1 and not self.is_cjk(clean_t) and not clean_t.isalnum()

            # [é€»è¾‘] æ ‡é¢˜é˜²ç²˜è¿æ£€æµ‹
            # å¦‚æœä» Header å˜æˆäº† Bodyï¼Œä¸”ä¸æ˜¯æ ‡ç‚¹ -> é€šå¸¸éœ€è¦æ’å…¥ç©ºè¡Œåˆ‡æ–­
            should_split = (last_type == "header" and current_type == "body" and not is_punctuation)
            if should_split:
                # [è±å… 1] å¦‚æœæ˜¯ä¸‰çº§æ ‡é¢˜ (###)ï¼Œå…è®¸ç´§æ¥å†…å®¹
                if line_prefix.strip() == "###": should_split = False
                # [è±å… 2] å¦‚æœæ˜¯æ³¨è„šç¬¦å· ([^1] æˆ– â‘ )ï¼Œå…è®¸ç´§æ¥æ ‡é¢˜ï¼Œä¸åˆ‡æ–­
                if re.match(r'^([\u2460-\u2469]|\d+)$', clean_t): should_split = False
                # [è±å… 3] è‹¥æ•´è¡Œæ˜¯æ ‡é¢˜è¡Œ (#/##)ï¼Œæ ‡é¢˜ä¸å†…å®¹åº”ä¸€ä½“ï¼Œä¸åˆ‡æ–­ï¼ˆé¿å… "# \n\n å†…å®¹"ï¼‰
                if line_prefix.strip() in ("#", "##"): should_split = False

            if should_split:
                formatted_text += "\n\n"

            if not is_punctuation:
                last_type = current_type

            # SUBTITLE (å‰¯æ ‡é¢˜) ç‰¹æ®Šå¤„ç†ï¼šåŠ ç²—
            span_prefix = ""
            if FONT_MAP:
                closest = min(FONT_MAP.keys(), key=lambda k: abs(k - size))
                if abs(closest - size) < 0.5:
                    span_prefix = FONT_MAP[closest]

            if span_prefix == "SUBTITLE":
                if formatted_text and not formatted_text.endswith("\n"):
                    formatted_text += "\n\n"
                text = f"**{text.strip()}**"

            # æ›¿æ¢æ³¨è„šç¬¦å·ä¸º Markdown æ ¼å¼ [^n]
            def replace_ref_body(_match):
                note_id = self.global_note_id
                self.global_note_id += 1
                page_note_queue.append(note_id)
                return f"[^{note_id}]"

            # æ­£åˆ™åŒ¹é… â‘  åˆ° â‘© (\u2460 - \u2469)
            text = re.sub(r'[\u2460-\u2469]', replace_ref_body, text)

            # [é€»è¾‘] åº”ç”¨è¡Œå†…æ ·å¼ (åŠ ç²—/æ–œä½“)
            # åªæœ‰å½“è¿™ä¸€è¡Œä¸æ˜¯æ ‡é¢˜æ—¶æ‰åº”ç”¨ï¼Œé¿å… ### **Title** è¿™ç§å†—ä½™
            if not line_prefix.startswith("#"):
                # PyMuPDF flags: é€šè¿‡äºŒè¿›åˆ¶ä½æ¥å­˜å‚¨ä¿¡æ¯çš„ intã€‚ç”¨ä½è¿ç®—æ¥è§£è¯»å®ƒï¼š
                # 0=æ™®é€šï¼Œ1=ä¸Šæ ‡ï¼Œ2=æ–œä½“ï¼Œ4=è¡¬çº¿ï¼Œ8=æ— è¡¬çº¿ï¼Œ16=ç²—ä½“ï¼Œ32=ç­‰å®½ï¼Œç›¸åŠ å¯ä»¥ç»„åˆ
                is_bold = flags & 16
                is_italic = flags & 2

                if "hei" in font_lower or "bold" in font_lower: is_bold = True
                if "kai" in font_lower: is_italic = True

                if is_bold or is_italic:
                    # [å…³é”®ä¿®å¤]ï¼šåªåŒ…è£¹æ ¸å¿ƒæ–‡å­—ï¼Œä¸åŒ…è£¹é¦–å°¾ç©ºæ ¼
                    # é¿å… "**    Text**" -> å¯¼è‡´æ— æ³• strip æ‰ç¼©è¿›
                    # æ”¹ä¸º "    **Text**" -> æœ€åçš„ strip() å¯ä»¥å»æ‰ç¼©è¿›

                    if not text.strip():
                        pass  # å¦‚æœå…¨æ˜¯ç©ºæ ¼ï¼Œå°±ä¸åŠ ç²—äº†
                    else:
                        # 1. æå–å·¦è¾¹ç©ºæ ¼
                        l_stripped = text.lstrip()
                        prefix_space = text[:len(text) - len(l_stripped)]

                        # 2. æå–å³è¾¹ç©ºæ ¼
                        r_stripped = text.rstrip()
                        suffix_space = text[len(r_stripped):]

                        # 3. æå–æ ¸å¿ƒæ–‡å­—
                        content = text.strip()

                        # 4. åŒ…è£¹æ ¸å¿ƒæ–‡å­—
                        if is_bold and is_italic:
                            content = f"***{content}***"
                        elif is_bold:
                            content = f"**{content}**"
                        elif is_italic:
                            content = f"*{content}*"

                        # 5. æ‹¼å›å»
                        text = prefix_space + content + suffix_space

            formatted_text += text

        # --- æ­¥éª¤ 4: æ™ºèƒ½åå¤„ç† (å»ç©º & ç¼©è¿›æ¸…æ´—) ---
        formatted_text = formatted_text.strip()  # åœ¨è¿™é‡Œç»Ÿä¸€è¿›è¡Œæ•´ä½“å»ç©º

        if line_prefix.strip().startswith("#"):
            # [æ ¸å¿ƒä¿®å¤] æ ‡é¢˜æ™ºèƒ½å»ç©º
            # ç›®æ ‡ï¼šä¿ç•™åºå·åçš„ç©ºæ ¼ (å¦‚ "ä¸€ å‡ ç‚¹è¯´æ˜")ï¼Œåˆ é™¤æ’ç‰ˆç”¨çš„ç©ºæ ¼ (å¦‚ "ç¼– è¾‘ éƒ¨")
            prefix_len = len(line_prefix)
            content = formatted_text[prefix_len:]
            content_norm = content.replace("ã€€", " ") # å½’ä¸€åŒ–å…¨è§’ç©ºæ ¼
            # æ­£åˆ™åŒ¹é…ï¼šæ•°å­—/ä¸­æ–‡åºå· + ç©ºæ ¼ + å†…å®¹
            match_num = re.match(r'^([0-9\.]+|[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+[ã€\.]?)\s+(.*)', content_norm)

            if match_num:
                # å‘½ä¸­åºå·ç»“æ„ -> ä¿ç•™ä¸€ä¸ªæ ‡å‡†ç©ºæ ¼
                num_part = match_num.group(1)
                text_part = match_num.group(2).replace(" ", "")
                content = f"{num_part} {text_part}"
            else:
                # æœªå‘½ä¸­ -> æš´åŠ›æ¸…ç†æ‰€æœ‰ç©ºæ ¼
                content = content.replace(" ", "").replace("ã€€", "")

            formatted_text = line_prefix + content

        elif line_prefix.strip().startswith(">"):
            # [æ ¸å¿ƒä¿®å¤] å¼•ç”¨å—å»ç¼©è¿›
            # å¼ºåˆ¶å»é™¤å¼•ç”¨å†…å®¹å‰çš„ç©ºç™½ï¼Œé˜²æ­¢ Markdown å°†å…¶æ¸²æŸ“ä¸ºä»£ç å—
            prefix_len = len(line_prefix)
            content = formatted_text[prefix_len:].strip()
            formatted_text = line_prefix + content

        return formatted_text, line_prefix

    def append_to_buffer(self, clean_line, is_new_para):
        """
        å°†å¤„ç†å¥½çš„å•è¡Œæ–‡æœ¬è¿½åŠ åˆ°ç¼“å†²åŒºï¼Œå¤„ç†è·¨è¡Œæ‹¼æ¥é€»è¾‘
        """
        # 1. å¼•ç”¨æ‹¼æ¥é€»è¾‘
        # å¦‚æœæ˜¯åŒç±»å‹å¼•ç”¨ç»­è¡Œï¼Œå»æ‰ "> " å‰ç¼€ç›´æ¥æ‹¼ï¼Œé˜²æ­¢æ¯è¡Œéƒ½æ–­å¼€
        # is_quote_continuation = False # å˜é‡è™½æœªä½¿ç”¨ä½†é€»è¾‘ä¿ç•™
        if clean_line.startswith("> ") and not is_new_para and self.current_para.startswith("> "):
            # is_quote_continuation = True
            clean_line = clean_line[2:]

        # 2. æ ‡é¢˜ç»­è¡Œæ‹¼æ¥ï¼šä¸Šä¸€æ®µæ˜¯æ ‡é¢˜ä¸”æœ¬è¡Œä¹Ÿæ˜¯æ ‡é¢˜ç»­è¡Œï¼Œå»æ‰ "#" å‰ç¼€å†æ‹¼
        if not is_new_para and self.current_para and re.match(r'^#+\s', self.current_para) and re.match(r'^#+\s', clean_line):
            clean_line = re.sub(r'^#+\s*', '', clean_line)

        if is_new_para:
            # æ–°æ®µè½ï¼šå°†æ—§æ®µè½æ¨å…¥ bufferï¼Œå¼€å§‹è®°å½•æ–°æ®µè½
            if self.current_para:
                self.body_buffer.append(self.current_para)
            self.current_para = clean_line
        else:
            # ç»­è¡Œï¼šæ‹¼æ¥åˆ°å½“å‰æ®µè½
            if self.current_para:
                merged = False

                # [æ ¸å¿ƒä¿®å¤] ç²—ä½“èåˆ (Bold Fusion)
                # åœºæ™¯ï¼šLine1: "**å¼€å§‹**" + Line2: "**ç»“æŸ**" -> "**å¼€å§‹ç»“æŸ**"
                # é¿å…å‡ºç° "**å¼€å§‹****ç»“æŸ**" å¯¼è‡´æ¸²æŸ“æ–­è£‚
                if self.current_para.endswith("**") and clean_line.startswith("**"):
                    raw_last = self.current_para[:-2][-1].replace("*", "").replace("`", "")
                    raw_curr = clean_line[2:][0].replace("*", "").replace("`", "")
                    if self.is_cjk(raw_last) and self.is_cjk(raw_curr):
                        self.current_para = self.current_para[:-2] + clean_line[2:]
                        merged = True

                # [æ ¸å¿ƒä¿®å¤] æ–œä½“èåˆ (Italic Fusion)
                # åœºæ™¯ï¼šLine1: "*ï¼ˆç¬‘å£°*" + Line2: "*ï¼Œé¼“æŒï¼‰*" -> "*ï¼ˆç¬‘å£°ï¼Œé¼“æŒï¼‰*"
                elif self.current_para.endswith("*") and clean_line.startswith("*") and not self.current_para.endswith(
                        "**") and not clean_line.startswith("**"):
                    raw_last = self.current_para[:-1][-1].replace("*", "").replace("`", "")
                    raw_curr = clean_line[1:][0].replace("*", "").replace("`", "")
                    if self.is_cjk(raw_last) and self.is_cjk(raw_curr):
                        self.current_para = self.current_para[:-1] + clean_line[1:]
                        merged = True

                if not merged:
                    # æ™®é€šæ–‡æœ¬æ‹¼æ¥ï¼šæ±‰å­—ä¹‹é—´ä¸åŠ ç©ºæ ¼ï¼Œè¥¿æ–‡ä¹‹é—´åŠ ç©ºæ ¼
                    last_char = self.current_para[-1].replace("*", "").replace("`", "")
                    curr_char = clean_line[0].replace("*", "").replace("`", "")

                    if self.is_cjk(last_char) and self.is_cjk(curr_char):
                        self.current_para += clean_line
                    else:
                        self.current_para += " " + clean_line
            else:
                self.current_para = clean_line

    def parse_chapter_pages(self, doc, page_indices, article_output_dir):
        """
        [ä¸»å…¥å£] è§£ææŒ‡å®šç« èŠ‚çš„é¡µé¢åˆ—è¡¨(è·¨é¡µæµå¼å¤„ç†)
        :param doc: PyMuPDF Document
        :param page_indices: è¿™ä¸€ç« åŒ…å«çš„é¡µç åˆ—è¡¨ (0-based)
        :param article_output_dir: æœ¬ç¯‡æ–‡ç« çš„è¾“å‡ºç›®å½•ï¼Œå›¾ç‰‡ä¿å­˜åœ¨å…¶ assets å­ç›®å½•
        """
        # è®¾ç½®æœ¬ç¯‡æ–‡ç« çš„ assets ç›®å½•
        self.assets_dir = article_output_dir / "assets"
        self.assets_dir.mkdir(parents=True, exist_ok=True)
        self.img_counter = 0

        # é‡ç½®çŠ¶æ€ (æ¯ç« å¼€å§‹)
        self.global_note_id = 1
        self.all_footnotes = []
        self.body_buffer = []
        self.current_para = ""

        # éå†ç« èŠ‚é‡Œçš„æ¯ä¸€é¡µå¹¶è§£æ
        for p_idx in page_indices:
            page = doc[p_idx]
            page_num = page.number + 1  # äººç±»é˜…è¯»é¡µç  (1-based)
            # è·å–åˆ†å‰²çº¿ä½ç½®ï¼ŒåŒºåˆ†æ­£æ–‡å’Œæ³¨è„š
            split_y = self.get_split_y(page)
            # è®¡ç®—è£å‰ªæ¡†ï¼šå»æ‰é¡µçœ‰
            actual_top_cut = min(MARGIN_TOP_CUT, split_y)
            # å»æ‰åº•éƒ¨æœ‰å¹²æ‰°ä¿¡æ¯çš„åŒºåŸŸ
            clip_bottom = min(MARGIN_BOTTOM_CUT, page.rect.height)
            # è·å–å†…å®¹
            clip_rect = fitz.Rect(0, actual_top_cut, page.rect.width, clip_bottom)
            data = page.get_text("dict", clip=clip_rect)

            body_lines_raw = [] # æ­£æ–‡åŒºåŸŸ
            foot_lines_raw = [] # è„šæ³¨åŒºåŸŸ
            page_note_queue = [] # å½“å‰é¡µé¢çš„æ³¨è„šå·é˜Ÿåˆ— (Body ç”Ÿäº§ ID -> Footer æ¶ˆè´¹ ID)

            # éå†å—ï¼Œåˆ†æµå›¾ç‰‡ã€æ­£æ–‡è¡Œã€æ³¨è„šè¡Œ
            for block in data["blocks"]:
                # --- å›¾ç‰‡å¤„ç† ---
                if "image" in block:
                    self.img_counter += 1
                    img_filename = f"img_{self.img_counter}.png"
                    img_path = self.assets_dir / img_filename
                    try:
                        with open(img_path, "wb") as f:
                            f.write(block["image"])
                        self.append_to_buffer(f"![img](assets/{img_filename})", is_new_para=True)
                    except Exception as e:
                        print(f"âš ï¸ å›¾ç‰‡ä¿å­˜å¤±è´¥ p{page_num}: {e}")
                    continue

                # --- æ–‡æœ¬å¤„ç† ---
                if "lines" not in block:
                    continue

                # æ ¹æ® Y åæ ‡åˆ’åˆ†åŒºåŸŸï¼Œåˆ†æµ
                if block["bbox"][1] >= split_y:
                    foot_lines_raw.extend(block["lines"])
                else:
                    body_lines_raw.extend(block["lines"])

            # === Pass 1: å¤„ç†æ­£æ–‡åŒºåŸŸ ===
            last_line_prefix = ""
            for line in body_lines_raw:
                line_text, prefix = self.process_spans_in_line(line, page_note_queue)
                # [æ³¨æ„] strip() åœ¨è¿™é‡Œè°ƒç”¨ï¼Œå»é™¤ Raw å­—ç¬¦ä¸²é‡Œçš„ç‰©ç†ç¼©è¿›
                clean_line = self.clean_text(line_text).strip()

                if not clean_line:
                    continue
                if re.search(r'[â€”_]{8,}', clean_line):
                    continue # è·³è¿‡åˆ†å‰²çº¿

                # æ™ºèƒ½åˆ†æ®µåˆ¤æ–­ï¼ˆlast_line_prefix ä¸ºä¸Šä¸€è¡Œçš„ prefixï¼Œç”¨äºæ ‡é¢˜ç»­è¡Œåˆ¤å®šï¼‰
                is_new = False

                # [åˆ¤å®š 1] ç‰©ç†ç¼©è¿› -> æ–°æ®µè½
                if line["bbox"][0] > INDENT_THRESHOLD:
                    is_new = True
                # [åˆ¤å®š 2] ç©ºæ ¼ç¼©è¿› (å…¨è§’/åŠè§’) -> æ–°æ®µè½
                raw_text = "".join([s["text"] for s in line["spans"]])
                if raw_text.startswith("ã€€") or raw_text.startswith("  "):
                    is_new = True

                # [åˆ¤å®š 3] æ ‡é¢˜å¼ºåˆ¶æ¢æ®µï¼ˆä½†è¿ç»­å¤šè¡ŒåŒæ ‡é¢˜è§†ä¸ºç»­è¡Œï¼Œåˆå¹¶ä¸ºä¸€è¡Œï¼‰
                if prefix.startswith("#"):
                    if last_line_prefix.strip().startswith("#"):
                        # ä¸Šä¸€è¡Œä¹Ÿæ˜¯æ ‡é¢˜ -> æ ‡é¢˜ç»­è¡Œï¼Œä¸æ¢æ®µ
                        is_new = False
                    else:
                        is_new = True

                # [åˆ¤å®š 4] å¼•ç”¨å—é€»è¾‘
                if prefix.startswith(">"):
                    # [æ ¸å¿ƒä¿®å¤] æ­£æ–‡/å¼•ç”¨é˜²ç²˜è¿
                    # å¦‚æœä¸Šä¸€æ®µæ˜¯æ­£æ–‡(ä¸å¸¦>)ï¼Œè¿™ä¸€æ®µæ˜¯å¼•ç”¨(å¸¦>) -> å¼ºåˆ¶æ¢æ®µ (å¦‚æ–‡æœ«å‡ºç‰ˆä¿¡æ¯)
                    if self.current_para and not self.current_para.startswith("> "):
                        is_new = True
                    elif not is_new:  # å¦‚æœæ˜¯å¼•ç”¨æ¥å¼•ç”¨ï¼Œä¸”æ— ç¼©è¿› -> è§†ä¸ºç»­è¡Œ
                        is_new = False

                # [æ ¸å¿ƒä¿®å¤] æ³¨è„šè·Ÿéš (å»æ‰ $)
                # å…è®¸æ³¨è„šç¬¦å·åè·Ÿæ–‡å­— (å¦‚ "[^1]ã€‚å†…å®¹") ç´§æ¥ä¸Šä¸€è¡Œ
                if re.match(r'^\s*\[\^\d+\]', clean_line):
                    is_new = False

                self.append_to_buffer(clean_line, is_new)
                last_line_prefix = prefix

            # === Pass 2: å¤„ç†é¡µåº•æ³¨è„šåŒºåŸŸ ===
            # åˆ—å®çš„ï¼šæ¯è¡Œéƒ½ç¼©è¿›ï¼Œåªæœ‰ â‘  åºå·çªå‡ºã€‚åªç”¨åºå·åˆ¤æ–­æ–°æ³¨è„šï¼Œä¸ç”¨ç¼©è¿›ã€‚ï¼ˆæ–¯å¤§æ—çš„ï¼šéœ€ç”¨ç¼©è¿›åˆ¤æ–­ï¼Œå› æ­£æ–‡ä¸æ³¨è„šå¸ƒå±€ç±»ä¼¼ï¼‰
            current_foot_para = ""
            for line in foot_lines_raw:
                raw_text = "".join([s["text"] for s in line["spans"]])
                clean_line = self.clean_text(raw_text).strip()
                if not clean_line:
                    continue
                if re.search(r'[â€”_]{8,}', clean_line):
                    continue

                # æ£€æµ‹æ³¨è„šå¼€å¤´æ˜¯å¦æœ‰ç¬¦å·ï¼šâ‘  æˆ– [^1]
                match = re.match(r'^[\u2460-\u2469]', clean_line)
                is_new_foot = False

                if match:
                    is_new_foot = True
                    # å°† PDF çš„åœˆåœˆæ•°å­—æ›¿æ¢ä¸º Markdown çš„ [^n]
                    if page_note_queue:
                        # ä»é˜Ÿåˆ—é¢†å·
                        note_id = page_note_queue.pop(0)
                        # æ›¿æ¢ç¬¦å·
                        clean_line = clean_line.replace(match.group(), f"[^{note_id}]: ", 1)
                    else:
                        # å¼‚å¸¸æƒ…å†µï¼šé¡µåº•æœ‰åœˆåœˆï¼Œä½†æ­£æ–‡æ²¡å¼•ç”¨ï¼Ÿ
                        # å…œåº•ï¼šç”Ÿæˆä¸€ä¸ªéšæœºIDæˆ–ä¿ç•™åŸæ ·
                        clean_line = clean_line.replace(match.group(), f"[^x]: ", 1)

                # æ‹¼æ¥æ³¨è„šæ–‡æœ¬ï¼ˆç»­è¡Œç›´æ¥æ‹¼ï¼Œä¸åŠ æ¢è¡Œï¼‰
                if is_new_foot:
                    if current_foot_para:
                        self.all_footnotes.append(current_foot_para)
                    current_foot_para = clean_line
                else:
                    if current_foot_para:
                        current_foot_para += clean_line
                    elif self.all_footnotes:
                        self.all_footnotes[-1] += clean_line
                    else:
                        current_foot_para = clean_line

            # æœ¬é¡µæœ€åä¸€ä¸ªæ³¨è„šæ®µè½
            if current_foot_para:
                self.all_footnotes.append(current_foot_para)

        # åˆ·æ–°æœ€åçš„æ­£æ–‡ç¼“å­˜
        if self.current_para:
            self.body_buffer.append(self.current_para)

        # === [æ ¸å¿ƒä¿®å¤] å¼•ç”¨å—æ™ºèƒ½åˆå¹¶ (Quote Merger) ===
        # å°†è¿ç»­çš„ä¸¤ä¸ªç‹¬ç«‹å¼•ç”¨å— (ä¸­é—´æœ‰ç©ºè¡Œ) åˆå¹¶ä¸ºä¸€ä¸ªå—
        merged_buffer = []
        for block in self.body_buffer:
            if not merged_buffer:
                merged_buffer.append(block)
                continue

            prev_block = merged_buffer[-1]
            # æ¡ä»¶ï¼šå‰ä¸€å—æ˜¯å¼•ç”¨ AND è¿™ä¸€å—ä¹Ÿæ˜¯å¼•ç”¨
            if prev_block.startswith("> ") and block.startswith("> "):
                # ä½¿ç”¨ "\n>\n" ä½œä¸ºç²˜åˆå‰‚ï¼Œä¿æŒè§†è§‰ä¸Šçš„åˆ†æ®µä½†é€»è¾‘ä¸Šæ˜¯ä¸€ä½“
                merged_buffer[-1] = prev_block + "\n>" + "\n" + block
            else:
                merged_buffer.append(block)

        # æœ€ç»ˆç»„è£…å…¨æ–‡
        full_md = "\n\n".join(merged_buffer)

        if self.all_footnotes:
            full_md += "\n\n" + "\n\n".join(self.all_footnotes)

        return full_md